# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "client<llm> GeminiFlash {\r\n  provider google-ai\r\n  options {\r\n    model gemini-2.5-flash\r\n    api_key env.GOOGLE_API_KEY\r\n  }\r\n}",
    "generators.baml": "generator lang_python {\r\n  output_type python/pydantic\r\n  output_dir \"../baml_client\"\r\n  version \"0.217.0\"\r\n}",
    "main.baml": "class Event {\r\n  timestamp string @description(\"ISO 8601 format timestamp of when event occurred\")\r\n  summary string @description(\"Brief description of event\")\r\n  sources string[] @description(\"List of X post IDs or URLs as sources for this event\")\r\n  media string? @description(\"Optional image or video URL associated with event\")\r\n  credibility_score float @description(\"0.0 to 1.0, higher is more credible\")\r\n  verified_sources int @description(\"Number of sources verified against knowledge base\")\r\n}\r\n\r\nclass Timeline {\r\n  topic string @description(\"The topic or query this timeline addresses\")\r\n  events Event[] @description(\"Chronological list of events\")\r\n  total_sources int @description(\"Total number of unique sources across all events\")\r\n  avg_credibility float @description(\"Average credibility score across all events\")\r\n  predictions string[]? @description(\"Optional what-if predictions based on observed patterns\")\r\n}\r\n\r\nclass KnowledgeFact {\r\n  fact_id string @description(\"Unique identifier for this fact\")\r\n  statement string @description(\"The factual statement\")\r\n  sources string[] @description(\"Sources that verify this fact\")\r\n  verification_status string @description(\"One of: 'verified', 'disputed', or 'unverified'\")\r\n  verified_at string @description(\"ISO timestamp when this fact was verified\")\r\n}\r\n\r\nclass Recommendation {\r\n  action string @description(\"Suggested action or follow-up query\")\r\n  reason string @description(\"Why this recommendation is being made\")\r\n}\r\n\r\nclass SessionMemory {\r\n  session_id string @description(\"Unique session identifier\")\r\n  query string @description(\"The query that was made\")\r\n  timestamp string @description(\"ISO timestamp of when query was made\")\r\n  results_count int @description(\"Number of results returned for query\")\r\n  relevance_score float @description(\"Relevance score of results (0.0 to 1.0)\")\r\n}\r\n\r\nclass XPost {\r\n  tweet_id string @description(\"Unique X post identifier\")\r\n  text string @description(\"Content of post\")\r\n  author string @description(\"Username of author\")\r\n  timestamp string @description(\"ISO timestamp when post was created\")\r\n  fave_count int @description(\"Number of favorites/likes\")\r\n  retweet_count int @description(\"Number of retweets\")\r\n  is_verified bool @description(\"Whether author is verified\")\r\n  media_urls string[] @description(\"List of media URLs (images, videos)\")\r\n  location string? @description(\"Optional location tag\")\r\n  credibility_score float @description(\"Calculated credibility score (0.0 to 1.0)\")\r\n}\r\n\r\nclass ProcessedQuery {\r\n  original_query string @description(\"The original user query\")\r\n  rewritten_query string @description(\"Optimized query for searching\")\r\n  entities string[] @description(\"Extracted entities from query\")\r\n  time_range string? @description(\"Inferred time range if any\")\r\n}\r\n\r\nclass CredibilityAssessment {\r\n  post_id string @description(\"ID of the post being assessed\")\r\n  credibility_score float @description(\"Overall credibility score (0.0 to 1.0)\")\r\n  factors string[] @description(\"Factors that influenced the score\")\r\n  reasoning string @description(\"Explanation for the assigned score\")\r\n}\r\n\r\nclass MisinformationAnalysis {\r\n  is_suspicious bool\r\n  suspicious_patterns string[]\r\n  risk_level string @description(\"low, medium, or high\")\r\n  recommendation string\r\n}\r\n\r\nfunction GenerateTimeline(query: string, retrieved_context: string, num_events: int) -> Timeline {\r\n  client GeminiFlash\r\n  prompt #\"\r\n    You are building a factual, chronological timeline for topic: {{ query }}\r\n\r\n    Below is retrieved context from verified X posts and knowledge base:\r\n\r\n    {{ retrieved_context }}\r\n\r\n    Generate a timeline with exactly {{ num_events }} events following these strict rules:\r\n\r\n    1. CHRONOLOGICAL ORDER: Events must be in strict chronological order (earliest first)\r\n    2. SOURCE CITATION: Each event must cite specific sources (X post IDs or URLs)\r\n    3. CREDIBILITY SCORES: Assign credibility scores based on:\r\n       - Source verification status\r\n       - Author verification\r\n       - Engagement quality (meaningful interactions, not just spam)\r\n       - Consistency with known facts\r\n    4. ACCURACY: Be accurate and ground everything in provided context\r\n    5. NO HALLUCINATION: Do not invent facts. Only use information from context\r\n    6. UNCERTAINTY HANDLING: If information is uncertain, mark credibility score low\r\n    7. PREDICTIONS (Optional): Generate 2-3 what-if predictions based on observed patterns\r\n\r\n    Return as a Timeline object with all required fields:\r\n    - topic: The main topic of this timeline\r\n    - events: Array of Event objects (each with timestamp, summary, sources, credibility_score, etc.)\r\n    - total_sources: Total unique sources across all events\r\n    - avg_credibility: Average credibility across all events (0.0 to 1.0)\r\n    - predictions: Optional array of predictions based on patterns\r\n\r\n    Format your response as valid JSON that matches the Timeline schema.\r\n  \"#\r\n}\r\n\r\nfunction ProcessQuery(original_query: string, context: string?) -> ProcessedQuery {\r\n  client GeminiFlash\r\n  prompt #\"\r\n    The user asked: {{ original_query }}\r\n\r\n    {% if context %}\r\n    Previous context: {{ context }}\r\n    {% endif %}\r\n\r\n    Rewrite this query to be more precise for searching X posts and knowledge base.\r\n    Focus on:\r\n    1. Specific entities (people, organizations, locations, events)\r\n    2. Time ranges if implied\r\n    3. Key themes or topics\r\n    4. Disambiguation (e.g., which \"Mumbai\" - city, district, etc.)\r\n\r\n    The rewritten query should be optimized for:\r\n    - Vector similarity search\r\n    - Keyword matching\r\n    - Metadata filtering\r\n\r\n    Extract the main entities mentioned.\r\n    Identify any implicit time ranges.\r\n\r\n    Return as a ProcessedQuery object with:\r\n    - original_query: The original query as provided\r\n    - rewritten_query: The optimized query\r\n    - entities: Array of key entities extracted\r\n    - time_range: Optional inferred time range if mentioned\r\n\r\n    Return only the object, nothing else.\r\n  \"#\r\n}\r\n\r\nfunction ExtractEntities(text: string) -> string[] {\r\n  client GeminiFlash\r\n  prompt #\"\r\n    Extract key entities from this text:\r\n\r\n    {{ text }}\r\n\r\n    Entities can be:\r\n    - People (names, roles)\r\n    - Organizations\r\n    - Locations (cities, regions, countries)\r\n    - Events (specific incidents, announcements)\r\n    - Dates and times\r\n    - Topics or themes\r\n\r\n    Return as an array of entity names, most important first (max 10 entities).\r\n    Only return the entity names, nothing else.\r\n  \"#\r\n}\r\n\r\nfunction AssessCredibility(post_text: string, author_info: string, engagement: string, knowledge_context: string?) -> CredibilityAssessment {\r\n  client GeminiFlash\r\n  prompt #\"\r\n    Assess the credibility of this X post:\r\n\r\n    POST CONTENT:\r\n    {{ post_text }}\r\n\r\n    AUTHOR INFO:\r\n    {{ author_info }}\r\n\r\n    ENGAGEMENT METRICS:\r\n    {{ engagement }}\r\n\r\n    {% if knowledge_context %}\r\n    CONTEXT FROM VERIFIED KNOWLEDGE BASE:\r\n    {{ knowledge_context }}\r\n    {% endif %}\r\n\r\n    Consider these factors when assessing credibility:\r\n\r\n    1. AUTHOR VERIFICATION:\r\n       - Is the author verified?\r\n       - Does the author have a history of credible posts?\r\n       - Is the author affiliated with a reputable organization?\r\n\r\n    2. CONTENT QUALITY:\r\n       - Does the content make factual claims or opinions?\r\n       - Is it specific with verifiable details (times, locations, names)?\r\n       - Does it cite sources or provide evidence?\r\n\r\n    3. ENGAGEMENT QUALITY:\r\n       - Is engagement organic or suspicious (botted)?\r\n       - Are comments/replies constructive or spammy?\r\n       - High-quality engagement from credible users increases credibility\r\n\r\n    4. CONSISTENCY:\r\n       - Is it consistent with known facts?\r\n       - Does it contradict verified information?\r\n       - Does it align with multiple independent sources?\r\n\r\n    5. RECENCY AND RELEVANCE:\r\n       - Is the content recent and relevant to current events?\r\n       - Is it being reported by multiple sources?\r\n\r\n    6. RED FLAGS (lower credibility):\r\n       - Excessive use of all-caps or emojis\r\n       - Conspiracy theories without evidence\r\n       - Clickbait language\r\n       - Anonymous or new accounts\r\n       - Overly emotional or sensational language\r\n\r\n    Assign a credibility score (0.0 to 1.0) where:\r\n    - 0.8 - 1.0: Highly credible (verified, well-sourced, consistent)\r\n    - 0.5 - 0.8: Moderately credible (some verification, reasonable)\r\n    - 0.2 - 0.5: Low credibility (unverified, some red flags)\r\n    - 0.0 - 0.2: Not credible (major red flags, contradictory)\r\n\r\n    Return as a CredibilityAssessment object with:\r\n    - post_id: Identifier for the post\r\n    - credibility_score: Float between 0.0 and 1.0\r\n    - factors: Array of key factors that influenced the score\r\n    - reasoning: Explanation for the assigned score\r\n  \"#\r\n}\r\n\r\nfunction DetectMisinformation(text: string) -> MisinformationAnalysis {\r\n  client GeminiFlash\r\n  prompt #\"\r\n    Analyze this text for potential misinformation patterns:\r\n\r\n    {{ text }}\r\n\r\n    Look for these suspicious patterns:\r\n\r\n    1. EMOTIONAL MANIPULATION:\r\n       - Exaggerated emotional language\r\n       - Fear-mongering\r\n       - Urgency (\"share this now!\")\r\n\r\n    2. MISLEADING HEADLINES:\r\n       - Clickbait titles\r\n       - Missing critical context\r\n       - Out-of-context quotes\r\n\r\n    3. SOURCE ISSUES:\r\n       - Anonymous claims without attribution\r\n       - \"Sources say\" without specifying\r\n       - Citing unreliable sources\r\n\r\n    4. FACTUAL INACCURACIES:\r\n       - Inconsistent timestamps\r\n       - Impossible claims\r\n       - Contradicts basic facts\r\n\r\n    5. NARRATIVE PATTERNS:\r\n       - Conspiracy theories\r\n       - \"They don't want you to know\" framing\r\n       - Over-simplification of complex issues\r\n\r\n    Assess risk level:\r\n    - LOW: No obvious red flags, minor issues\r\n    - MEDIUM: Some concerning patterns, verify before sharing\r\n    - HIGH: Multiple red flags, likely misinformation\r\n\r\n    Return as JSON with:\r\n    - is_suspicious: Boolean\r\n    - suspicious_patterns: Array of detected patterns\r\n    - risk_level: One of \"low\", \"medium\", or \"high\"\r\n    - recommendation: Action to take (verify, ignore, report, etc.)\r\n  \"#\r\n}\r\n\r\nfunction GenerateRecommendations(query: string, timeline: Timeline?, user_session: SessionMemory[]?) -> Recommendation[] {\r\n  client GeminiFlash\r\n  prompt #\"\r\n    Given this query and timeline:\r\n\r\n    QUERY: {{ query }}\r\n\r\n    {% if timeline %}\r\n    TIMELINE SUMMARY:\r\n    Topic: {{ timeline.topic }}\r\n    Events: {{ timeline.events.length }}\r\n    Avg Credibility: {{ timeline.avg_credibility }}\r\n    Sources: {{ timeline.total_sources }}\r\n    {% endif %}\r\n\r\n    {% if user_session %}\r\n    USER'S RECENT QUERIES:\r\n    {% for mem in user_session %}\r\n    - {{ mem.query }} (relevance: {{ mem.relevance_score }})\r\n    {% endfor %}\r\n    {% endif %}\r\n\r\n    Generate 3-5 context-aware recommendations for follow-up actions.\r\n    Consider:\r\n\r\n    1. DEEP DIVE OPPORTUNITIES:\r\n       - Are there events that need more investigation?\r\n       - Are there gaps in the timeline?\r\n       - Are there unverified claims to explore?\r\n\r\n    2. RELATED TOPICS:\r\n       - What related events or topics might the user be interested in?\r\n       - What happened before/after this timeline?\r\n       - What related locations or people are involved?\r\n\r\n    3. FACT-CHECKING SUGGESTIONS:\r\n       - Are there claims that should be verified against official sources?\r\n       - Are there contradictory accounts that need reconciliation?\r\n\r\n    4. PREDICTIVE INSIGHTS:\r\n       - Based on patterns, what might happen next?\r\n       - What should the user watch for?\r\n\r\n    5. USER INTEREST ALIGNMENT:\r\n       - Based on their recent queries, what else might interest them?\r\n\r\n    Return as an array of Recommendation objects, each with:\r\n    - action: Specific action or follow-up query\r\n    - reason: Why this is being recommended\r\n  \"#\r\n}",
    "simple_test.baml": "class SimpleEvent {\r\n  id string\r\n  summary string\r\n}\r\n\r\nfunction SimpleTest() -> SimpleEvent {\r\n  client \"openai/gpt-4o-mini\"\r\n  \r\n  prompt #\"\r\n    Create a simple event with id and summary.\r\n  \"#\r\n}\r\n",
}

def get_baml_files():
    return _file_map